{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "270750d1",
   "metadata": {},
   "source": [
    "# CREDIT CARD FRAUD DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b661c49",
   "metadata": {},
   "source": [
    "-Building a model to detect fraudulent credit card transaction using algorithm like logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe07a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eca6ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "card = pd.read_csv(r\"C:\\Users\\MAGOMA\\Documents\\CODSOFT\\machine_learning\\credit_card\\creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e29a65ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the first five rows\n",
    "card.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14671d9",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d79c9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Checking for the information about the data\n",
    "card.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8f67cc",
   "metadata": {},
   "source": [
    "From the above information, we can see that we do not have any missing value and the data types are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b1df324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.529912</td>\n",
       "      <td>0.873892</td>\n",
       "      <td>1.347247</td>\n",
       "      <td>0.145457</td>\n",
       "      <td>0.414209</td>\n",
       "      <td>0.100223</td>\n",
       "      <td>0.711206</td>\n",
       "      <td>0.176066</td>\n",
       "      <td>-0.286717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046949</td>\n",
       "      <td>0.208105</td>\n",
       "      <td>-0.185548</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.098816</td>\n",
       "      <td>-0.552904</td>\n",
       "      <td>-0.073288</td>\n",
       "      <td>0.023307</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.535388</td>\n",
       "      <td>0.865268</td>\n",
       "      <td>1.351076</td>\n",
       "      <td>0.147575</td>\n",
       "      <td>0.433680</td>\n",
       "      <td>0.086983</td>\n",
       "      <td>0.693039</td>\n",
       "      <td>0.179742</td>\n",
       "      <td>-0.285642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049526</td>\n",
       "      <td>0.206537</td>\n",
       "      <td>-0.187108</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.098117</td>\n",
       "      <td>-0.553471</td>\n",
       "      <td>-0.078306</td>\n",
       "      <td>0.025427</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>74.0</td>\n",
       "      <td>1.038370</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.184456</td>\n",
       "      <td>1.109950</td>\n",
       "      <td>0.441699</td>\n",
       "      <td>0.945283</td>\n",
       "      <td>-0.036715</td>\n",
       "      <td>0.350995</td>\n",
       "      <td>0.118950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>0.605089</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>-0.626463</td>\n",
       "      <td>0.479120</td>\n",
       "      <td>-0.166937</td>\n",
       "      <td>0.081247</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>74.0</td>\n",
       "      <td>1.038370</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.184456</td>\n",
       "      <td>1.109950</td>\n",
       "      <td>0.441699</td>\n",
       "      <td>0.945283</td>\n",
       "      <td>-0.036715</td>\n",
       "      <td>0.350995</td>\n",
       "      <td>0.118950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>0.605089</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>-0.626463</td>\n",
       "      <td>0.479120</td>\n",
       "      <td>-0.166937</td>\n",
       "      <td>0.081247</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>74.0</td>\n",
       "      <td>1.038370</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.184456</td>\n",
       "      <td>1.109950</td>\n",
       "      <td>0.441699</td>\n",
       "      <td>0.945283</td>\n",
       "      <td>-0.036715</td>\n",
       "      <td>0.350995</td>\n",
       "      <td>0.118950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>0.605089</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>-0.626463</td>\n",
       "      <td>0.479120</td>\n",
       "      <td>-0.166937</td>\n",
       "      <td>0.081247</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282987</th>\n",
       "      <td>171288.0</td>\n",
       "      <td>1.912550</td>\n",
       "      <td>-0.455240</td>\n",
       "      <td>-1.750654</td>\n",
       "      <td>0.454324</td>\n",
       "      <td>2.089130</td>\n",
       "      <td>4.160019</td>\n",
       "      <td>-0.881302</td>\n",
       "      <td>1.081750</td>\n",
       "      <td>1.022928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.524067</td>\n",
       "      <td>-1.337510</td>\n",
       "      <td>0.473943</td>\n",
       "      <td>0.616683</td>\n",
       "      <td>-0.283548</td>\n",
       "      <td>-1.084843</td>\n",
       "      <td>0.073133</td>\n",
       "      <td>-0.036020</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283483</th>\n",
       "      <td>171627.0</td>\n",
       "      <td>-1.464380</td>\n",
       "      <td>1.368119</td>\n",
       "      <td>0.815992</td>\n",
       "      <td>-0.601282</td>\n",
       "      <td>-0.689115</td>\n",
       "      <td>-0.487154</td>\n",
       "      <td>-0.303778</td>\n",
       "      <td>0.884953</td>\n",
       "      <td>0.054065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287217</td>\n",
       "      <td>0.947825</td>\n",
       "      <td>-0.218773</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>0.044127</td>\n",
       "      <td>0.639270</td>\n",
       "      <td>0.213565</td>\n",
       "      <td>0.119251</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283485</th>\n",
       "      <td>171627.0</td>\n",
       "      <td>-1.457978</td>\n",
       "      <td>1.378203</td>\n",
       "      <td>0.811515</td>\n",
       "      <td>-0.603760</td>\n",
       "      <td>-0.711883</td>\n",
       "      <td>-0.471672</td>\n",
       "      <td>-0.282535</td>\n",
       "      <td>0.880654</td>\n",
       "      <td>0.052808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284205</td>\n",
       "      <td>0.949659</td>\n",
       "      <td>-0.216949</td>\n",
       "      <td>0.083250</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>0.639933</td>\n",
       "      <td>0.219432</td>\n",
       "      <td>0.116772</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284191</th>\n",
       "      <td>172233.0</td>\n",
       "      <td>-2.667936</td>\n",
       "      <td>3.160505</td>\n",
       "      <td>-3.355984</td>\n",
       "      <td>1.007845</td>\n",
       "      <td>-0.377397</td>\n",
       "      <td>-0.109730</td>\n",
       "      <td>-0.667233</td>\n",
       "      <td>2.309700</td>\n",
       "      <td>-1.639306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391483</td>\n",
       "      <td>0.266536</td>\n",
       "      <td>-0.079853</td>\n",
       "      <td>-0.096395</td>\n",
       "      <td>0.086719</td>\n",
       "      <td>-0.451128</td>\n",
       "      <td>-1.183743</td>\n",
       "      <td>-0.222200</td>\n",
       "      <td>55.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284193</th>\n",
       "      <td>172233.0</td>\n",
       "      <td>-2.691642</td>\n",
       "      <td>3.123168</td>\n",
       "      <td>-3.339407</td>\n",
       "      <td>1.017018</td>\n",
       "      <td>-0.293095</td>\n",
       "      <td>-0.167054</td>\n",
       "      <td>-0.745886</td>\n",
       "      <td>2.325616</td>\n",
       "      <td>-1.634651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402639</td>\n",
       "      <td>0.259746</td>\n",
       "      <td>-0.086606</td>\n",
       "      <td>-0.097597</td>\n",
       "      <td>0.083693</td>\n",
       "      <td>-0.453584</td>\n",
       "      <td>-1.205466</td>\n",
       "      <td>-0.213020</td>\n",
       "      <td>36.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1081 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "33          26.0 -0.529912  0.873892  1.347247  0.145457  0.414209  0.100223   \n",
       "35          26.0 -0.535388  0.865268  1.351076  0.147575  0.433680  0.086983   \n",
       "113         74.0  1.038370  0.127486  0.184456  1.109950  0.441699  0.945283   \n",
       "114         74.0  1.038370  0.127486  0.184456  1.109950  0.441699  0.945283   \n",
       "115         74.0  1.038370  0.127486  0.184456  1.109950  0.441699  0.945283   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "282987  171288.0  1.912550 -0.455240 -1.750654  0.454324  2.089130  4.160019   \n",
       "283483  171627.0 -1.464380  1.368119  0.815992 -0.601282 -0.689115 -0.487154   \n",
       "283485  171627.0 -1.457978  1.378203  0.811515 -0.603760 -0.711883 -0.471672   \n",
       "284191  172233.0 -2.667936  3.160505 -3.355984  1.007845 -0.377397 -0.109730   \n",
       "284193  172233.0 -2.691642  3.123168 -3.339407  1.017018 -0.293095 -0.167054   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "33      0.711206  0.176066 -0.286717  ...  0.046949  0.208105 -0.185548   \n",
       "35      0.693039  0.179742 -0.285642  ...  0.049526  0.206537 -0.187108   \n",
       "113    -0.036715  0.350995  0.118950  ...  0.102520  0.605089  0.023092   \n",
       "114    -0.036715  0.350995  0.118950  ...  0.102520  0.605089  0.023092   \n",
       "115    -0.036715  0.350995  0.118950  ...  0.102520  0.605089  0.023092   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "282987 -0.881302  1.081750  1.022928  ... -0.524067 -1.337510  0.473943   \n",
       "283483 -0.303778  0.884953  0.054065  ...  0.287217  0.947825 -0.218773   \n",
       "283485 -0.282535  0.880654  0.052808  ...  0.284205  0.949659 -0.216949   \n",
       "284191 -0.667233  2.309700 -1.639306  ...  0.391483  0.266536 -0.079853   \n",
       "284193 -0.745886  2.325616 -1.634651  ...  0.402639  0.259746 -0.086606   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "33      0.001031  0.098816 -0.552904 -0.073288  0.023307    6.14      0  \n",
       "35      0.000753  0.098117 -0.553471 -0.078306  0.025427    1.77      0  \n",
       "113    -0.626463  0.479120 -0.166937  0.081247  0.001192    1.18      0  \n",
       "114    -0.626463  0.479120 -0.166937  0.081247  0.001192    1.18      0  \n",
       "115    -0.626463  0.479120 -0.166937  0.081247  0.001192    1.18      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "282987  0.616683 -0.283548 -1.084843  0.073133 -0.036020   11.99      0  \n",
       "283483  0.082926  0.044127  0.639270  0.213565  0.119251    6.82      0  \n",
       "283485  0.083250  0.044944  0.639933  0.219432  0.116772   11.93      0  \n",
       "284191 -0.096395  0.086719 -0.451128 -1.183743 -0.222200   55.66      0  \n",
       "284193 -0.097597  0.083693 -0.453584 -1.205466 -0.213020   36.74      0  \n",
       "\n",
       "[1081 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for duplicate rows across all columns\n",
    "drows = card[card.duplicated()]\n",
    "drows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8105972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the duplicated rows\n",
    "card.drop_duplicates(card.iloc[:, :], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fb4000f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Time, V1, V2, V3, V4, V5, V6, V7, V8, V9, V10, V11, V12, V13, V14, V15, V16, V17, V18, V19, V20, V21, V22, V23, V24, V25, V26, V27, V28, Amount, Class]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 31 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming if we removed the duplicated rows\n",
    "\n",
    "d = card[card.duplicated()]\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1867358b",
   "metadata": {},
   "source": [
    "Now we managed to remove all duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50a22721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the unique values under column Class\n",
    "card['Class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94323c96",
   "metadata": {},
   "source": [
    "##### For column Class:\n",
    "0 means legitimate and\n",
    "1 means fraudulent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4767d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Class', ylabel='count'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count plot for both legitimate and fraudulent transactions\n",
    "\n",
    "sns.countplot(x='Class', data=card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ad4fe83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      473\n",
       "V1        473\n",
       "V2        473\n",
       "V3        473\n",
       "V4        473\n",
       "V5        473\n",
       "V6        473\n",
       "V7        473\n",
       "V8        473\n",
       "V9        473\n",
       "V10       473\n",
       "V11       473\n",
       "V12       473\n",
       "V13       473\n",
       "V14       473\n",
       "V15       473\n",
       "V16       473\n",
       "V17       473\n",
       "V18       473\n",
       "V19       473\n",
       "V20       473\n",
       "V21       473\n",
       "V22       473\n",
       "V23       473\n",
       "V24       473\n",
       "V25       473\n",
       "V26       473\n",
       "V27       473\n",
       "V28       473\n",
       "Amount    473\n",
       "Class     473\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the number of fraudulent transactions\n",
    "card[card['Class']==1].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82d1875",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06988d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = card.drop(columns = ['Time', 'Class'])\n",
    "y = card['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "683a4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75ad7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test sets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4d8d8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train : (198608, 29)\n",
      "x_test (85118, 29)\n"
     ]
    }
   ],
   "source": [
    "# Checking for the shapes of train data and test data\n",
    "print('x_train :', x_train.shape)\n",
    "print('x_test', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "889d172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the logistic regression \n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "13ba7113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAGOMA\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4919d93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions from test data\n",
    "pred = lr.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1da1e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76f3131e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45301074178798084"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how good our mmodel can be\n",
    "r2_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c605f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4d4fbf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae438617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpred = dtc.predict(x_test)\n",
    "dpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e286c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32974555683879336"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, dpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c040f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cbd8be76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84941    47]\n",
      " [   40    90]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, dpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7153526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "05b883b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     84988\n",
      "           1       0.66      0.69      0.67       130\n",
      "\n",
      "    accuracy                           1.00     85118\n",
      "   macro avg       0.83      0.85      0.84     85118\n",
      "weighted avg       1.00      1.00      1.00     85118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, dpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bed71486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "63eeee43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "049066e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "156af145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e2029b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.676428889508383"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "60dc582a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     84988\n",
      "           1       0.94      0.72      0.82       130\n",
      "\n",
      "    accuracy                           1.00     85118\n",
      "   macro avg       0.97      0.86      0.91     85118\n",
      "weighted avg       1.00      1.00      1.00     85118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1500cc54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
